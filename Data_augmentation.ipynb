{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation techniques such as flipping, scaling, noise addition, random rotations, flipping, zooming, and shifting also brghtness variation have to be implemented using Python libraries such as Albumentations, YOLOv8 or similar image processing tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_dir, img_dir, transform=None, target_transform=None):\n",
    "        self.annotations_dir = annotations_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.img_files = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image Path\n",
    "        img_name = self.img_files[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Label Path and Parsing\n",
    "        label_path = os.path.join(self.annotations_dir, img_name.replace('jpg', 'txt'))\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                data = list(map(float, line.strip().split()))\n",
    "                class_id, bbox = data[0], data[1:]\n",
    "                # Add bounding box and class label to respective lists\n",
    "                labels.append(int(class_id))\n",
    "                boxes.append(bbox)  # bounding box coordinates\n",
    "\n",
    "        # Convert boxes and labels to tensors\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            boxes = self.target_transform(boxes)\n",
    "            labels = self.target_transform(labels)\n",
    "\n",
    "        return image, {'boxes': boxes, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import tv_tensors\n",
    "\n",
    "H, W = 32, 32\n",
    "img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)\n",
    "\n",
    "# Define image transformations\n",
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    \n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),  # Or Resize(antialias=True)\n",
    "    v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8)\n",
    "boxes = torch.randint(0, H // 2, size=(3, 4))\n",
    "boxes[:, 2:] += boxes[:, :2]\n",
    "boxes = tv_tensors.BoundingBoxes(boxes, format=\"XYXY\", canvas_size=(H, W))\n",
    "\n",
    "img, boxes = transforms(img, boxes)\n",
    "# And you can pass arbitrary input structures\n",
    "output_dict = transforms({\"image\": img, \"boxes\": boxes})\n",
    "\n",
    "WeedDataset = CustomDataset(annotations_dir= 'Data/luxeed_heatmaps/data/labels', img_dir='Data/luxeed_heatmaps/data/images', transform=transforms)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
